{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from utils.metric import evaluate, evaluate_multi_cls\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(pkl_path, loc):\n",
    "    with open(pkl_path, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    pos_data, neg_data = [], []\n",
    "    for d in data:\n",
    "        if d['label'] == 0:\n",
    "            pos_data.append(d[loc])\n",
    "        else:\n",
    "            neg_data.append(d[loc])\n",
    "    pos_data = torch.stack(pos_data).float()\n",
    "    neg_data = torch.stack(neg_data).float()\n",
    "    # assert pos_data.shape[0] == neg_data.shape[0]\n",
    "    return pos_data, neg_data\n",
    "\n",
    "def read_data_all(pkl_path):\n",
    "    with open(pkl_path, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    pos_data, neg_data = [], []\n",
    "    for d in data:\n",
    "        if d['label'] == 0:\n",
    "            pos_data.append(d)\n",
    "        else:\n",
    "            neg_data.append(d)\n",
    "    return pos_data, neg_data\n",
    "\n",
    "def mix_data_fitting(x_train, y_train, model_name='lr'):\n",
    "    model_list = []\n",
    "    for layer in range(x_train.shape[1]):\n",
    "        if model_name == 'lda':\n",
    "            model = LinearDiscriminantAnalysis()\n",
    "        elif model_name == 'lr':\n",
    "            model = LogisticRegression(penalty='l2')\n",
    "        elif model_name == 'sgd':\n",
    "            model = SGDClassifier(loss='log_loss')\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        model.fit(x_train[:, layer], y_train)\n",
    "        model_list.append(model)\n",
    "    return model_list\n",
    "\n",
    "def evaluation(x_val, y_val, model_list, shot=0, threshold=0.5):\n",
    "    accs_mlp, asrs_mlp, prs_mlp, f1s_mlp, auroc_mlp = [], [], [], [], []\n",
    "    pos_results, neg_results = [], []\n",
    "    for layer, model in enumerate(model_list):\n",
    "        x_l = x_val[:, layer]\n",
    "        y_l = y_val\n",
    "        if shot > 0:\n",
    "            model.partial_fit(x_val[:shot, layer], y_val[:shot], classes=[0,1])\n",
    "            x_l = x_val[shot:, layer]\n",
    "            y_l = y_val[shot:]\n",
    "        y_pred = model.predict_proba(x_l)[:, 1]\n",
    "        print(y_l)\n",
    "        print(y_pred)\n",
    "        acc, asr, pr, f1, auroc, neg_per_sample_result, pos_per_sample_result = \\\n",
    "            evaluate_multi_cls(y_l, y_pred, show=False, threshold=threshold, enable_analyse=True)\n",
    "        # pos_results.append(pos_per_sample_result)\n",
    "        # neg_results.append(neg_per_sample_result)\n",
    "        accs_mlp.append(acc)\n",
    "        asrs_mlp.append(asr)\n",
    "        prs_mlp.append(pr)\n",
    "        f1s_mlp.append(f1)\n",
    "        auroc_mlp.append(auroc)\n",
    "    return accs_mlp, asrs_mlp, prs_mlp, f1s_mlp, auroc_mlp, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split_multi_cls(train_data,train_label_list, num_shot=10):\n",
    "    total_num = train_data.shape[0]\n",
    "    train_num = int(num_shot) if num_shot != -1 else total_num\n",
    "    val_num = total_num - train_num\n",
    "    # class_indices = {}\n",
    "\n",
    "    # for index, label in enumerate(train_label_list):\n",
    "    #     if str(label.item()) not in class_indices:\n",
    "    #         class_indices[str(label.item())] = []\n",
    "    #     class_indices[str(label.item())].append(index)\n",
    "\n",
    "    # selected_indices = []\n",
    "    # for label, indices in class_indices.items():\n",
    "    #     selected = random.sample(indices, 2)  # 从每类中随机选择两个索引\n",
    "    #     selected_indices.extend(selected) \n",
    "\n",
    "    train_idx = random.sample(range(total_num), train_num)\n",
    "\n",
    "    val_idx = list(set(range(total_num)) - set(train_idx))\n",
    "\n",
    "    x_train = torch.cat([train_data[train_idx]], dim=0)\n",
    "    y_train = torch.cat([train_label_list[train_idx]], dim=0)\n",
    "    # print('train_label',y_train)\n",
    "    x_val = torch.cat([train_data[val_idx]], dim=0)\n",
    "    y_val = torch.cat([train_label_list[val_idx]])\n",
    "    # print(y_val)\n",
    "\n",
    "    return x_train, y_train, x_val, y_val\n",
    "\n",
    "def read_data_single(pkl_path, key_words ,loc):\n",
    "    with open(pkl_path, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    pos_data, neg_data = [], []\n",
    "    num_neg=0\n",
    "    num_pos=0\n",
    "    for d in data:\n",
    "        # print(d.keys())\n",
    "        if key_words in d['img_path'] and d['label']==1:\n",
    "            neg_data.append(d[loc])\n",
    "            num_neg+=1\n",
    "    for d in data:\n",
    "        if d['label'] == 0:\n",
    "            pos_data.append(d[loc])\n",
    "            num_pos+=1\n",
    "        if num_pos==num_neg:\n",
    "            break\n",
    "    print(key_words,num_neg,num_pos)\n",
    "    pos_data = torch.stack(pos_data).float()\n",
    "    neg_data = torch.stack(neg_data).float()\n",
    "    assert pos_data.shape[0] == neg_data.shape[0]\n",
    "    return pos_data, neg_data\n",
    "\n",
    "def get_fine_grained_data(data, top_k_indices):\n",
    "    return data[:, top_k_indices[:, 0], top_k_indices[:, 1]].reshape(data.shape[0], 1, -1)\n",
    "    # dh = data.shape[-1]\n",
    "    # return data[:, top_k_indices[:, 0], top_k_indices[:, 1]].reshape(data.shape[0], -1, dh).sum(1).unsqueeze(1)\n",
    "\n",
    "def few_shot_probing_multi_cls(train_data, train_label_list, num_shot, num_repeat=10, threshold=0.5, model_name='lr'):\n",
    "    model_list = []\n",
    "    accs, asrs, f1s, aurocs = [], [], [], []\n",
    "    for _ in tqdm(range(num_repeat)):\n",
    "        if len(train_data.shape) > 3:   # 'attn_headas'\n",
    "            n, nl, nh, dh = train_data.shape\n",
    "            train_data= train_data.reshape(n, -1, dh)\n",
    "        train_label_tensor=torch.Tensor(train_label_list)    \n",
    "        x_train, y_train, x_val, y_val = train_val_split_multi_cls(train_data, train_label_tensor, num_shot=num_shot)\n",
    "        print(x_train.shape)\n",
    "        print(y_train)\n",
    "        models = mix_data_fitting(x_train, y_train, model_name=model_name)\n",
    "        model_list.append(models)\n",
    "        accs_mlp= evaluation(x_val, y_val, models, threshold=threshold)\n",
    "        accs.append(accs_mlp)\n",
    "        # asrs.append(asrs_mlp)\n",
    "        # f1s.append(f1s_mlp)\n",
    "        # aurocs.append(auroc_mlp)\n",
    "\n",
    "    return {\n",
    "        'acc': np.array(accs),\n",
    "        # 'asr': np.array(asrs),\n",
    "        # 'f1': np.array(f1s),\n",
    "        # 'auroc': np.array(aurocs),\n",
    "        # 'threshold': threshold\n",
    "    }, model_list\n",
    "\n",
    "def testing(test_data, labels, model_list, shot=0, threshold=0.5):\n",
    "    accs, asrs, f1s, aurocs = [], [], [], []\n",
    "    for models in tqdm(model_list):\n",
    "        if len(test_data.shape) > 3:   # 'attn_headas'\n",
    "            n, nl, nh, dh = test_data.shape\n",
    "            test_data = test_data.reshape(n, -1, dh)\n",
    "        x_val = test_data\n",
    "        y_val = labels\n",
    "        accs_mlp= evaluation(x_val, y_val, models, shot=shot, threshold=threshold)\n",
    "        accs.append(accs_mlp)\n",
    "        # asrs.append(asrs_mlp)\n",
    "        # f1s.append(f1s_mlp)\n",
    "        # aurocs.append(auroc_mlp)\n",
    "    return {\n",
    "        'acc': np.array(accs),\n",
    "        # 'asr': np.array(asrs),\n",
    "        # 'f1': np.array(f1s),\n",
    "        # 'auroc': np.array(aurocs),\n",
    "        # 'threshold': threshold\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_data_list = []\n",
    "neg_data_list = []\n",
    "\n",
    "for i in range(1, 14):\n",
    "    prefix = f\"{i:02d}-\"\n",
    "    pos, neg = read_data_single('output/LLaVA-7B/raw_mmsafety_SD_TYPO_all_oe_activations.pkl', prefix, loc='attn_heads')\n",
    "    pos_data_list.append(pos)\n",
    "    neg_data_list.append(neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### copy attn_heads_indices from 2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_indices_llava = np.array([[ 4, 30],\n",
    "        [ 5,  2],\n",
    "        [ 6, 22],\n",
    "        [ 6, 29],\n",
    "        [ 7,  0],\n",
    "        [ 7,  7],\n",
    "        [ 7, 26],\n",
    "        [ 8,  0],\n",
    "        [ 8,  9],\n",
    "        [ 8, 21],\n",
    "        [ 8, 30],\n",
    "        [ 9, 20],\n",
    "        [10,  5],\n",
    "        [10, 22],\n",
    "        [11,  0],\n",
    "        [11,  1],\n",
    "        [11, 21],\n",
    "        [13, 17],\n",
    "        [14, 14],\n",
    "        [15,  1],\n",
    "        [15,  6],\n",
    "        [16,  7],\n",
    "        [16, 25],\n",
    "        [16, 29],\n",
    "        [17,  7],\n",
    "        [20,  6],\n",
    "        [22,  6],\n",
    "        [22, 15],\n",
    "        [23,  4],\n",
    "        [27, 11],\n",
    "        [28,  2],\n",
    "        [28, 13]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_indices_qwen =  np.array([[ 0,  0],\n",
    "        [ 3, 11],\n",
    "        [ 4, 25],\n",
    "        [ 5,  5],\n",
    "        [ 5, 28],\n",
    "        [ 5, 29],\n",
    "        [ 6, 28],\n",
    "        [ 7, 24],\n",
    "        [ 8, 15],\n",
    "        [10,  1],\n",
    "        [10, 29],\n",
    "        [11,  2],\n",
    "        [11, 28],\n",
    "        [12,  7],\n",
    "        [12,  8],\n",
    "        [12,  9],\n",
    "        [12, 13],\n",
    "        [13,  9],\n",
    "        [13, 19],\n",
    "        [13, 27],\n",
    "        [15,  0],\n",
    "        [15, 16],\n",
    "        [17, 14],\n",
    "        [18, 22],\n",
    "        [19,  1],\n",
    "        [20, 12],\n",
    "        [20, 13],\n",
    "        [22, 15],\n",
    "        [26,  0],\n",
    "        [28,  9],\n",
    "        [30, 11],\n",
    "        [31, 21]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Multi_cls of 13 types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "test_data = []\n",
    "pos_data_list = [globals()[f'pos_data_{i:02d}'] for i in range(1, 14)]\n",
    "neg_data_list = [globals()[f'neg_data_{i:02d}'] for i in range(1, 14)]\n",
    "train_label_list=[]\n",
    "test_label_list=[]\n",
    "for i,neg_data in enumerate(neg_data_list):\n",
    "    num_train = int(0.1 * neg_data.shape[0])  #10%data用于训练\n",
    "    \n",
    "    train_data.append(neg_data[:num_train])  \n",
    "    test_data.append(neg_data[num_train:])\n",
    "    train_label_list+=[i+1]*num_train\n",
    "    test_label_list+=[i+1]*(neg_data.shape[0]-num_train)\n",
    "\n",
    "train_data = torch.cat(train_data, dim=0)  # [13 * 10%, 32, 32, 128]\n",
    "test_data = torch.cat(test_data, dim=0) \n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "print(train_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 加载数据\n",
    "with open('/workspace/safety_heads/Attack/output/LLaVA-7B/raw_mmsafety_SD_TYPO_all_oe_activations.pkl', 'rb') as file:\n",
    "# with open('output/qwen/raw_mmsafety_SD_TYPO_all_oe_activations.pkl', 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "    # print(data[0].keys())\n",
    "all_class_data = {key: [] for key in range(14)}\n",
    "for d in data:\n",
    "    all_class_data[d['scenario']].append(d['attn_heads'])\n",
    "for k, v in all_class_data.items():\n",
    "    all_class_data[k] = get_fine_grained_data(torch.stack(v), top_k_indices_llava).squeeze(1)\n",
    "    # all_class_data[k] = get_fine_grained_data(torch.stack(v), top_k_indices_qwen).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_class_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratios = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "num_repeat = 20\n",
    "accs_dict = {ratio: [] for ratio in train_ratios}\n",
    "all_data = []\n",
    "\n",
    "log_output = []\n",
    "\n",
    "for train_ratio in train_ratios:\n",
    "    print(f\"\\nTraining with {train_ratio*100}% of data\")\n",
    "    all_metrics = []\n",
    "\n",
    "    for _ in tqdm(range(num_repeat)):\n",
    "        X_train, X_test, y_train, y_test = [], [], [], []\n",
    "        \n",
    "        for k, v in all_class_data.items():\n",
    "            per_class_num = v.shape[0]\n",
    "            num_train = int(train_ratio * per_class_num)\n",
    "            num_train = max(1, min(num_train, per_class_num - 1))\n",
    "            \n",
    "            train_idx = random.sample(range(per_class_num), num_train)\n",
    "            val_idx = list(set(range(per_class_num)) - set(train_idx))\n",
    "            \n",
    "            # print(v.shape, v[train_idx].shape, v[val_idx].shape)\n",
    "            X_train.append(v[train_idx])\n",
    "            X_test.append(v[val_idx])\n",
    "            y_train.append(torch.ones(num_train) * k)\n",
    "            y_test.append(torch.ones(per_class_num - num_train) * k)\n",
    "        \n",
    "        X_train = torch.cat(X_train)\n",
    "        X_test = torch.cat(X_test)\n",
    "        y_train = torch.cat(y_train)\n",
    "        y_test = torch.cat(y_test)\n",
    "\n",
    "        X_train = X_train.to(torch.float32)\n",
    "        X_test = X_test.to(torch.float32)\n",
    "        \n",
    "        model = LDA()\n",
    "        model.fit(X_train.numpy(), y_train.numpy())\n",
    "        y_pred = model.predict(X_test.numpy())\n",
    "        \n",
    "        acc = accuracy_score(y_test.numpy(), y_pred)\n",
    "        accs_dict[train_ratio].append(acc)\n",
    "\n",
    "        # classification_report，默认返回float类别！\n",
    "        # 可以设置target_names = [str(i) for i in range(14)]，或者在后续处理时float(cls)\n",
    "        report = classification_report(y_test.numpy(), y_pred, output_dict=True, zero_division=0, target_names = [str(i) for i in range(14)]) \n",
    "        # print(report)\n",
    "        all_metrics.append(report)\n",
    "\n",
    "    acc_array = np.array(accs_dict[train_ratio])\n",
    "    mean_acc = acc_array.mean()\n",
    "    std_acc = acc_array.std()\n",
    "    acc_log = f\"Ratio {train_ratio}: Mean accuracy = {mean_acc:.4f}, Std = {std_acc:.4f}\"\n",
    "    log_output.append(acc_log)\n",
    "    # print(acc_log)\n",
    "\n",
    "    avg_metrics = {str(k): {'precision': [], 'recall': [], 'f1-score': []} for k in range(14)}\n",
    "    for report in all_metrics:\n",
    "        for cls in range(14):\n",
    "            cls_str = str(cls)\n",
    "            # print(cls_str)\n",
    "            if cls_str in report:\n",
    "                avg_metrics[cls_str]['precision'].append(report[cls_str]['precision'])\n",
    "                avg_metrics[cls_str]['recall'].append(report[cls_str]['recall'])\n",
    "                avg_metrics[cls_str]['f1-score'].append(report[cls_str]['f1-score'])\n",
    "\n",
    "    detailed_log = [f\"\\nDetailed metrics for ratio {train_ratio}:\"]\n",
    "    detailed_log.append(\"Class | Precision | Recall | F1-Score\")\n",
    "    detailed_log.append(\"-\" * 45)\n",
    "    # print(f\"\\nDetailed metrics for ratio {train_ratio}:\")\n",
    "    # print(\"Class | Precision | Recall | F1-Score\")\n",
    "    # print(\"-\" * 45)\n",
    "\n",
    "    class_metrics = {}\n",
    "    for cls in range(14):\n",
    "        cls_str = str(cls)\n",
    "        mean_precision = np.mean(avg_metrics[cls_str]['precision'])\n",
    "        mean_recall = np.mean(avg_metrics[cls_str]['recall'])\n",
    "        mean_f1 = np.mean(avg_metrics[cls_str]['f1-score'])\n",
    "        class_log = f\"{cls:5d} | {mean_precision:.4f}    | {mean_recall:.4f} | {mean_f1:.4f}\"\n",
    "        detailed_log.append(class_log)\n",
    "        # print(class_log)\n",
    "        \n",
    "        class_metrics[cls_str] = {\n",
    "            'precision': float(mean_precision),\n",
    "            'recall': float(mean_recall),\n",
    "            'f1-score': float(mean_f1),\n",
    "            'precision_list': [float(x) for x in avg_metrics[cls_str]['precision']],\n",
    "            'recall_list': [float(x) for x in avg_metrics[cls_str]['recall']],\n",
    "            'f1_score_list': [float(x) for x in avg_metrics[cls_str]['f1-score']]\n",
    "        }\n",
    "    log_output.extend(detailed_log)\n",
    "    mean_values = {\n",
    "        'train_ratio': train_ratio,\n",
    "        'mean_acc': float(mean_acc),\n",
    "        'mean_std': float(std_acc),\n",
    "        'class_metrics': {\n",
    "            str(k): {\n",
    "                'precision': float(np.mean(avg_metrics[str(k)]['precision'])),\n",
    "                'recall': float(np.mean(avg_metrics[str(k)]['recall'])),\n",
    "                'f1-score': float(np.mean(avg_metrics[str(k)]['f1-score']))\n",
    "            } for k in range(14)\n",
    "        }\n",
    "    }\n",
    "    all_data.append(mean_values)\n",
    "\n",
    "# json save\n",
    "output_dir = 'test_fine_detector_cross_Muilt_CLS'\n",
    "output_file = os.path.join(output_dir, 'data_llava_lda_detailed.json')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "with open(output_file, 'w') as json_file:\n",
    "    json.dump(all_data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "# log save\n",
    "log_file = os.path.join(output_dir, 'data_llava_lda_detailed_log.txt')\n",
    "with open(log_file, 'w') as log_f:\n",
    "    log_f.write(\"\\n\".join(log_output))\n",
    "\n",
    "print(f\"\\nResults saved to {output_file}\")\n",
    "print(f\"Log saved to {log_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zjy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
